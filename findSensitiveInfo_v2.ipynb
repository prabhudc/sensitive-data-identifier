{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import json\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_emails(text):\n",
    "        \"\"\" Returns e-mail addresses [tag: EMAIL] \"\"\"\n",
    "        emails_regex = \"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,4}\"\n",
    "        emails_re = re.compile(emails_regex)\n",
    "        emails_list = [(\"EMAIL\", email) for email in emails_re.findall(text)]\n",
    "        return emails_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_phoneNumber(text, regex=None):\n",
    "        \"\"\" Returns phone numbers\"\"\"\n",
    "\n",
    "        if not regex:\n",
    "            # Using US phone regex as default\n",
    "            regex = r'''(\\b\n",
    "                                \\d{3}     # area code is 3 digits (e.g. '800')\n",
    "                                \\D*         # optional separator is any number of non-digits\n",
    "                                \\d{3}     # trunk is 3 digits (e.g. '555')\n",
    "                                \\D*         # optional separator\n",
    "                                \\d{4}\\b     # rest of number is 4 digits (e.g. '1212')\n",
    "                                )'''\n",
    "        \n",
    "        phone_re = re.compile(regex, re.VERBOSE)\n",
    "        phone_list = [(\"PHONE\", phone) for phone in phone_re.findall(text)]\n",
    "        return phone_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_urls(text):\n",
    "        \"\"\" Returns URLs\"\"\"\n",
    "        url_regex = r'''\n",
    "                        (?xi)\n",
    "                            \\b\n",
    "                            (                           \n",
    "                            (?:\n",
    "                                [a-z][\\w-]+:                \n",
    "                                (?:\n",
    "                                /{1,3}                        \n",
    "                                |                             \n",
    "                                [a-z0-9%]                     \n",
    "                                                                \n",
    "                                )\n",
    "                                |                           \n",
    "                                www\\d{0,3}[.]               \n",
    "                                |                           \n",
    "                                [a-z0-9.\\-]+[.][a-z]{2,4}/  \n",
    "                            )\n",
    "                            (?:                           \n",
    "                                [^\\s()<>]+                      \n",
    "                                |                               \n",
    "                                \\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)  \n",
    "                            )+\n",
    "                            (?:                           \n",
    "                                \\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)  \n",
    "                                |                                   \n",
    "                                [^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]\n",
    "                            )\n",
    "                        )'''\n",
    "\n",
    "        url_re = re.compile(url_regex, re.VERBOSE)\n",
    "        url_list = [(\"URL\", url[0]) for url in url_re.findall(text)]\n",
    "        return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_singaporeID(text):\n",
    "        \"\"\"Returns Singapore National ID based on  characters and length long\"\"\"\n",
    "        ids_list = []\n",
    "        ends=['N','S','R']\n",
    "        starts=['G','S']\n",
    "        for sent in nltk.sent_tokenize(text):\n",
    "            for word in nltk.word_tokenize(sent):\n",
    "                if len(word) >=8 and any(word.startswith(start) for start in starts) and any(word.endswith(end) for end in ends) and any(char.isdigit() for char in word):\n",
    "                    ids_list.append((\"Singapore ID\", word))\n",
    "        return ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ids(text):\n",
    "        \"\"\"Returns IDs based on length - needs work to make it accurate\"\"\"\n",
    "        ids_list = []\n",
    "        for sent in nltk.sent_tokenize(text):\n",
    "            for word in nltk.word_tokenize(sent):\n",
    "                if len(word) >= 4 and len(word)<=8 and any(char.isdigit() for char in word):\n",
    "                    ids_list.append((\"ID\", word))\n",
    "        return ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_twitterID(text):\n",
    "        \"\"\"Returns Twitter usernames\n",
    "        \"\"\"\n",
    "        twitter_regex = r'^|[^@\\w](@\\w{1,15})\\b'\n",
    "        twitter_re = re.compile(twitter_regex)\n",
    "        twitter_list = [(\"TWITTER\", twitter) for twitter in twitter_re.findall(\n",
    "            text) if twitter != \"\"]\n",
    "        return twitter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk import Tree\n",
    "\n",
    "def get_chunks(text, label):\n",
    "    chunked = nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(text)))\n",
    "    prev = None\n",
    "    continuous_chunk = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for subtree in chunked:\n",
    "        if type(subtree) == nltk.Tree and subtree.label() == label:\n",
    "            current_chunk.append(\" \".join([token for token, pos in subtree.leaves()]))\n",
    "        elif current_chunk:\n",
    "            named_entity = \" \".join(current_chunk)\n",
    "            if named_entity not in continuous_chunk:\n",
    "                continuous_chunk.append(named_entity)\n",
    "                current_chunk = []\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return continuous_chunk\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_location(text,label='GPE'):\n",
    "    loc_list = [('Location', loc ) for loc in get_chunks(text, label)]\n",
    "    return loc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_creditCard(text):\n",
    "        \"\"\"Returns CC Info based on length - can also find out if its AMEX or not\"\"\"\n",
    "        cc_regex=r'''(\\b(?:\\d[ -]*?){13,16}\\b)'''\n",
    "        cc_re = re.compile(cc_regex, re.VERBOSE)\n",
    "        cc_list=[]\n",
    "        for ccInfo in cc_re.findall(text):\n",
    "            if len(ccInfo) ==15:\n",
    "                cc_list.append((\"CreditCard-AMEX\", ccInfo))\n",
    "            else:\n",
    "                cc_list.append((\"CreditCard\", ccInfo))\n",
    "        return cc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sensitive_data(text, **kwargs):\n",
    "        \"\"\" Returns sensitive info\n",
    "        \"\"\"\n",
    "        return  find_singaporeID(text)+  \\\n",
    "                find_twitterID(text) + \\\n",
    "                find_emails(text) + \\\n",
    "                find_urls(text) + \\\n",
    "                find_phoneNumber(text)+ \\\n",
    "                find_location(text)+ \\\n",
    "                find_creditCard(text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of files to be processed\n",
    "arr_file_list = [\"output_10_oliver_twist.txt\",\n",
    "                 \"output_03_hamlet.txt\",\n",
    "                 \"output_02_romeo_juliet.txt\",\n",
    "                ]\n",
    "\n",
    "v_doc_count = 0\n",
    "\n",
    "# output file\n",
    "f_run_log = open('run_log.txt','w')\n",
    "\n",
    "# 1. loop through each file\n",
    "# 2. Analize the POS tags\n",
    "# 3. Evaluate the risk of each word\n",
    "for _file in arr_file_list: \n",
    "    \n",
    "    v_doc_count  += 1\n",
    "    \n",
    "    v_file_in = 'files/'+_file\n",
    "    v_file_out = 'files/output_'+_file\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Initialize variables to collect and print content\n",
    "    s_singaporeID =  set([])\n",
    "    s_twitterID =  set([])\n",
    "    s_emails =  set([])\n",
    "    s_urls =  set([])\n",
    "    s_phoneNumber =  set([])\n",
    "    s_location =  set([])\n",
    "    s_creditCard =  set([])\n",
    "    v_line_count = 0\n",
    "    v_singaporeID_count = 0\n",
    "    v_twitterID_count = 0\n",
    "    v_emails_count = 0\n",
    "    v_urls_count = 0\n",
    "    v_phoneNumber_count = 0\n",
    "    v_location_count = 0\n",
    "    v_creditCard_count = 0\n",
    "    \n",
    "    f_sens = open(v_file_in,'r')\n",
    "    \n",
    "    \n",
    "    for line_raw in f_sens:\n",
    "        v_line_count += 1\n",
    "        line = line_raw.encode(\"utf-8\")\n",
    "        if len(find_singaporeID(line))>0:\n",
    "            s_singaporeID.add(str(find_singaporeID(line)))\n",
    "            v_singaporeID_count += 1\n",
    "        if len(find_twitterID(line))>0:\n",
    "            s_twitterID.add(str(find_twitterID(line)))\n",
    "            v_twitterID_count += 1\n",
    "        if len(find_emails(line))>0:\n",
    "            s_emails.add(str(find_emails(line)))\n",
    "            v_emails_count += 1\n",
    "        if len(find_urls(line))>0:\n",
    "            s_urls.add(str(find_urls(line)))\n",
    "            v_urls_count += 1\n",
    "        if len(find_phoneNumber(line))>0:\n",
    "            s_phoneNumber.add(str(find_phoneNumber(line)))\n",
    "            v_phoneNumber_count += 1\n",
    "        if len(find_location(line))>0:\n",
    "            s_location.add(str(find_location(line)))\n",
    "            v_location_count += 1\n",
    "        if len(find_creditCard(line))>0:\n",
    "            s_creditCard.add(str(find_creditCard(line)))\n",
    "            v_creditCard_count += 1   \n",
    "    f_sens.close()\n",
    "    f_run_log.write(\"Document number being processed : \" + str(v_doc_count))\n",
    "    f_run_log.write(\"\\n\\nTotal number of lines in the file : \" + str(v_line_count))\n",
    "    f_run_log.write(\"\\n\\nTotal number occurrences of Singaporean IDs in the file : \" + str(v_singaporeID_count))\n",
    "    f_run_log.write((\"====> The Singapore IDs are \" + str(s_singaporeID)).encode(\"utf-8\"))\n",
    "    f_run_log.write(\"\\n\\nTotal number of occurrences Twitter IDs in the file : \" + str(v_twitterID_count))\n",
    "    f_run_log.write((\"====> The Twitter IDs are \" + str(s_twitterID)).encode(\"utf-8\"))\n",
    "    f_run_log.write(\"\\n\\nTotal number of occurrences Email IDs in the file : \" + str(v_emails_count))\n",
    "    f_run_log.write((\"====> The Email IDs are \" + str(s_emails)).encode(\"utf-8\"))\n",
    "    f_run_log.write(\"\\n\\nTotal number of occurrences URLs in the file : \" + str(v_urls_count))\n",
    "    f_run_log.write((\"====> The URLs are \" + str(s_urls)).encode(\"utf-8\"))\n",
    "    f_run_log.write(\"\\n\\nTotal number of occurrences Ph Numbers in the file : \" + str(v_phoneNumber_count))\n",
    "    f_run_log.write((\"====> The Phone numbers are \" + str(s_phoneNumber)).encode(\"utf-8\"))\n",
    "    f_run_log.write(\"\\n\\nTotal number of occurrences Addresses in the file : \" + str(v_location_count))\n",
    "    f_run_log.write((\"====> The Addresses are \" + str(s_location)).encode(\"utf-8\"))\n",
    "    f_run_log.write(\"\\n\\nTotal number of occurrences Credit Cards in the file : \" + str(v_creditCard_count))\n",
    "    f_run_log.write((\"====> The credit-card numbers are \" + str(s_creditCard)).encode(\"utf-8\"))\n",
    "    f_run_log.write(\"\\n$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\n\")\n",
    "v_doc_count = 0\n",
    "f_run_log.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Demo Code below</h4>\n",
    "Each function explaining each feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1.</b> Test for sensitive email content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EMAIL', 'ipd2@illinois.edu')]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_emails(\"my email id is ipd2@illinois.edu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.</b> Test for sensitive phone number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PHONE', '7237724501')]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_phoneNumber(\"You can contact my manager at +7237724501\", regex=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3.</b> Test for web-URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('URL', 'http://www.mugglenet.com/')]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_urls(\"If you think you're a muggle - You ought to visit http://www.mugglenet.com/ \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>4.</b> Test for social Singaporean social security IDs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Singapore ID', 'G9443425N')]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    find_singaporeID('G9443425N')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>5.</b> Test for twitter handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TWITTER', '@gandalf')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_twitterID('If you''re caught by an obscurian, tweet me @gandalf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>6.</b> Test for address locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Location', 'St'), ('Location', 'North')]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_location(\"I need to fix my sleigh. I live at Santa Claus 325,St. Santa Claus Lane, North Pole\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>6.</b> Test for credit-card numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CreditCard', '5510399013453413')]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_creditCard(\"My card with number 5510399013453413 seems to be blocked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>7.</b> Combined test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Singapore ID', 'G1413425N'),\n",
       " ('TWITTER', '@GreyWizard'),\n",
       " ('EMAIL', 'gandalf_the_grey@wizards.com'),\n",
       " ('URL', 'https://wizard-world.com'),\n",
       " ('PHONE', '7237724000'),\n",
       " ('Location', 'North Mirkwood'),\n",
       " ('CreditCard', '5520-3277-9345-9498')]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_sensitive_data(\"I am Gandalf the Wizard, I live at Pinewood, North Mirkwood forest. My social realms are @GreyWizard. \\\n",
    "                    I pay my credit card bills to 5520-3277-9345-9498 with my glorious staff. If you need my help, call me at \\\n",
    "                    +7237724000 or email me at gandalf_the_grey@wizards.com. I shall come to thy help, unless I am busy with busy with my social media profile at https://wizard-world.com \\\n",
    "                    My exclusive wizrd-id is G1413425N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
